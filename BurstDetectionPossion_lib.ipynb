{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"1001\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  var JS_MIME_TYPE = 'application/javascript';\n",
       "  var HTML_MIME_TYPE = 'text/html';\n",
       "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    var script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    var cell = handle.cell;\n",
       "\n",
       "    var id = cell.output_area._bokeh_element_id;\n",
       "    var server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null && id in Bokeh.index) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            var id = msg.content.text.trim();\n",
       "            if (id in Bokeh.index) {\n",
       "              Bokeh.index[id].model.document.clear();\n",
       "              delete Bokeh.index[id];\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    var output_area = handle.output_area;\n",
       "    var output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      var bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      var script_attrs = bk_div.children[0].attributes;\n",
       "      for (var i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      var toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    var el = document.getElementById(\"1001\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = css_urls.length + js_urls.length;\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "\n",
       "    function on_error() {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    for (var i = 0; i < css_urls.length; i++) {\n",
       "      var url = css_urls[i];\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }\n",
       "\n",
       "    const hashes = {\"https://cdn.bokeh.org/bokeh/release/bokeh-2.2.3.min.js\": \"T2yuo9Oe71Cz/I4X9Ac5+gpEa5a8PpJCDlqKYO0CfAuEszu1JrXLl8YugMqYe3sM\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.2.3.min.js\": \"98GDGJ0kOMCUMUePhksaQ/GYgB3+NH9h996V88sh3aOiUNX3N+fLXAtry6xctSZ6\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.2.3.min.js\": \"89bArO+nlbP3sgakeHjCo1JYxYR5wufVgA3IbUvDY+K7w4zyxJqssu7wVnfeKCq8\"};\n",
       "\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      if (url in hashes) {\n",
       "        element.crossOrigin = \"anonymous\";\n",
       "        element.integrity = \"sha384-\" + hashes[url];\n",
       "      }\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "  };\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  \n",
       "  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.2.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.2.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.2.3.min.js\"];\n",
       "  var css_urls = [];\n",
       "  \n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    function(Bokeh) {\n",
       "    \n",
       "    \n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if (root.Bokeh !== undefined || force === true) {\n",
       "      \n",
       "    for (var i = 0; i < inline_js.length; i++) {\n",
       "      inline_js[i].call(root, root.Bokeh);\n",
       "    }\n",
       "    if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(\"1001\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(css_urls, js_urls, function() {\n",
       "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(\"1001\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    const hashes = {\"https://cdn.bokeh.org/bokeh/release/bokeh-2.2.3.min.js\": \"T2yuo9Oe71Cz/I4X9Ac5+gpEa5a8PpJCDlqKYO0CfAuEszu1JrXLl8YugMqYe3sM\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.2.3.min.js\": \"98GDGJ0kOMCUMUePhksaQ/GYgB3+NH9h996V88sh3aOiUNX3N+fLXAtry6xctSZ6\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.2.3.min.js\": \"89bArO+nlbP3sgakeHjCo1JYxYR5wufVgA3IbUvDY+K7w4zyxJqssu7wVnfeKCq8\"};\n\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      if (url in hashes) {\n        element.crossOrigin = \"anonymous\";\n        element.integrity = \"sha384-\" + hashes[url];\n      }\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  \n  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.2.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.2.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.2.3.min.js\"];\n  var css_urls = [];\n  \n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    function(Bokeh) {\n    \n    \n    }\n  ];\n\n  function run_inline_js() {\n    \n    if (root.Bokeh !== undefined || force === true) {\n      \n    for (var i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n    if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(\"1001\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "from sys import exit\n",
    "from lxml import etree\n",
    "from scipy import signal \n",
    "from sklearn import preprocessing\n",
    "from scipy import optimize\n",
    "import regex as re\n",
    "import timeit\n",
    "from scipy.signal import butter, lfilter\n",
    "from scipy.signal import freqz\n",
    "from lmfit.models import StepModel, LinearModel\n",
    "import sys, importlib, os\n",
    "import McsPy.McsData\n",
    "import McsPy.McsCMOS\n",
    "from McsPy import ureg, Q_\n",
    "from numpy import trapz\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "import h5py\n",
    "import pickle\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.stats import skew\n",
    "from scipy.stats import kurtosis\n",
    "%matplotlib inline\n",
    "import itertools\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import statsmodels.api as sm # to build a LOWESS model\n",
    "from scipy.interpolate import interp1d \n",
    "import os\n",
    "import changefinder\n",
    "from bokeh.io import output_notebook, show\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.models import LinearColorMapper, ColorBar\n",
    "output_notebook()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def find_peak(count):\n",
    "    \n",
    "    \"\"\"Function to extract peaks in ISI distribution of the spike trains\"\"\"\n",
    "    \n",
    "    t1=np.diff(np.sign(np.diff(count))) #counts \n",
    "    peak_ind=np.where(t1==(-2))[0]+1\n",
    "    diff_peak_ind=np.diff(peak_ind)\n",
    "    \n",
    "    \n",
    "    ####print(peak_ind, 'peaks')\n",
    "    ####print( diff_peak_ind, 'diff peaks')\n",
    "    \n",
    "    \n",
    "   \n",
    "    \n",
    "    if len(diff_peak_ind[diff_peak_ind<=2])>0:\n",
    "        \n",
    "        to_delete=[]\n",
    "        \n",
    "        ####print('while loop')\n",
    "\n",
    "        compinds=np.where(np.diff(peak_ind)<=2)[0].tolist()\n",
    "        \n",
    "        for compind in compinds:\n",
    "            \n",
    "            p_ind1=peak_ind[compind]\n",
    "            p_ind2=peak_ind[compind+1]\n",
    "            \n",
    "            if count[p_ind1]>count[p_ind2]:\n",
    "                \n",
    "                to_delete.append(compind+1)\n",
    "            else: \n",
    "                to_delete.append(compind)\n",
    "                \n",
    "        peak_ind=np.delete(peak_ind, to_delete)\n",
    "        \n",
    "    return peak_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def peak(count, bins, th):\n",
    "    \n",
    "    \"\"\"Function to extract peaks in ISI distribution of the spike trains\"\"\"\n",
    "    \n",
    "    t1=np.diff(np.sign(np.diff(count))) #counts \n",
    "    peak_ind=np.where(t1==(-2))[0]+1\n",
    "    diff_peak_ind=np.diff(peak_ind)\n",
    "    \n",
    "    \n",
    "    ##print(peak_ind, 'peaks')\n",
    "    ##print( diff_peak_ind, 'diff peaks')\n",
    "    \n",
    "    \n",
    "   \n",
    "    \n",
    "    if len(diff_peak_ind[diff_peak_ind<=2])>0:\n",
    "        \n",
    "        to_delete=[]\n",
    "        \n",
    "        ##print('while loop')\n",
    "\n",
    "        compinds=np.where(np.diff(peak_ind)<=2)[0].tolist()\n",
    "        \n",
    "        for compind in compinds:\n",
    "            \n",
    "            p_ind1=peak_ind[compind]\n",
    "            p_ind2=peak_ind[compind+1]\n",
    "            \n",
    "            if count[p_ind1]>count[p_ind2]:\n",
    "                \n",
    "                to_delete.append(compind+1)\n",
    "            else: \n",
    "                to_delete.append(compind)\n",
    "                \n",
    "        peak_ind=np.delete(peak_ind, to_delete)\n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "    ###print(peak_ind, 'after filter')\n",
    "            \n",
    "    fp=0\n",
    "    sp=1\n",
    "    spi=0\n",
    "    fpi=0\n",
    "    ind_peak=None\n",
    "    ISIth=None\n",
    "    mp=max(bins)\n",
    "    \n",
    "    \n",
    "    ##print(bins[peak_ind], 'isis')\n",
    "    \n",
    "    if len(peak_ind)>=2:\n",
    "        \n",
    "        ###print('two peaks ', bins[peak_ind])\n",
    "        \n",
    "        test_bin=bins[peak_ind]\n",
    "        \n",
    "        \n",
    "        if len(test_bin[test_bin<np.log10(th)])>0:\n",
    "            \n",
    "            ####print('yes, smaller')\n",
    "            \n",
    "        \n",
    "\n",
    "            for index, ind in enumerate(peak_ind):\n",
    "                \n",
    "                ###print(index, 'index here')\n",
    "\n",
    "                if (bins[ind]<np.log10(th)) and (count[ind]>fp): \n",
    "                    \n",
    "                    ###print(ind, 'index existed')#finds max peak left than 11!! not adapitive\n",
    "\n",
    "                    fp=count[ind] #peak count \n",
    "                    fpi=ind\n",
    "                    ind_peak=index\n",
    "                    \n",
    "                    \n",
    "                    # peak index \n",
    "                    \n",
    "                    ###print(peak_ind[(ind_peak+1):], 'peakindexesremained')\n",
    "\n",
    "                    for i in peak_ind[(ind_peak+1):]:  #for peak following burst peak find minimim count? strange\n",
    "                        gmin=min(count[fpi:i])\n",
    "                        \n",
    "                        ####print(gmin, 'gmin')##finding the void  between burst and following peak\n",
    "\n",
    "                        geomin=np.sqrt((count[fpi])*(count[i])) \n",
    "                        \n",
    "                        ###print(geomin, 'geomin')#geometric mean of peaks\n",
    "\n",
    "                        #this works for some reason: \n",
    "                        #could have been, peak with smallest geometric mean \n",
    "\n",
    "                        #the principle is no spikes between bursts (as if all neurons where involved)\n",
    "                        \n",
    "                        ###print(1-(gmin/geomin), 'geo')\n",
    "\n",
    "\n",
    "                        if (1-(1-(gmin/geomin)) <sp) and (1-(gmin/geomin)>0.35): #if where two peak having most rare ISIs in between whose are burst peak and pause\n",
    "                            sp=1-(1-(gmin/geomin))\n",
    "                            spi=i\n",
    "                            ISIth=bins[np.argmin(count[fpi:spi])]\n",
    "                        \n",
    "                            \n",
    "\n",
    "        else:\n",
    "            for index, ind in enumerate(peak_ind):\n",
    "                \n",
    "                ###print(index, 'index here')\n",
    "                 \n",
    "                if (bins[ind]<mp): \n",
    "                    \n",
    "                    ###print(ind, 'index existed')#finds max peak left than 11!! not adapitive\n",
    "\n",
    "                    mp=bins[ind] #peak count \n",
    "                    fpi=ind\n",
    "                    ind_peak=index\n",
    "                    \n",
    "                    \n",
    "                    # peak index \n",
    "                    \n",
    "                    ###print(peak_ind[(ind_peak+1):], 'peakindexesremained')\n",
    "\n",
    "                    for i in peak_ind[(ind_peak+1):]:  #for peak following burst peak find minimim count? strange\n",
    "                        gmin=min(count[fpi:i])\n",
    "                        \n",
    "                        ###print(gmin, 'gmin')##finding the void  between burst and following peak\n",
    "\n",
    "                        geomin=np.sqrt((count[fpi])*(count[i])) \n",
    "                        \n",
    "                       # ##print(geomin, 'geomin')#geometric mean of peaks\n",
    "\n",
    "                        #this works for some reason: \n",
    "                        #could have been, peak with smallest geometric mean \n",
    "\n",
    "                        #the principle is no spikes between bursts (as if all neurons where involved)\n",
    "                        \n",
    "                        ###print(1-(gmin/geomin), 'geo')\n",
    "\n",
    "\n",
    "                        if (1-(1-(gmin/geomin)) <sp) and (1-(gmin/geomin)>0.35): #if where two peak having most rare ISIs in between whose are burst peak and pause\n",
    "                            sp=1-(1-(gmin/geomin))\n",
    "                            spi=i\n",
    "                            ISIth=bins[np.argmin(count[fpi:spi])]\n",
    "                        \n",
    "                           \n",
    "                            \n",
    "    return (ISIth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def LogISI(sp, f, th):\n",
    "    \n",
    "    \"\"\"Function to  detect burst-like spike trains\n",
    "    sp: spiketrain\n",
    "    th: threshold\"\"\"\n",
    "    \n",
    "    Bursts=[]\n",
    "    \n",
    "    bind=[]\n",
    "    merge=[]\n",
    "    \n",
    "\n",
    "    ISI=np.log10(np.diff(sp))\n",
    "    \n",
    "    #f=len(sp)/((sp[-1]-sp[0])/1000000)\n",
    "    \n",
    "    \n",
    "    \n",
    "    test_surprise=[]\n",
    "    #log values of spikes\n",
    "    \n",
    "    count, bins=np.histogram(ISI, bins=np.arange(0, np.max(ISI)+0.2, 0.1))\n",
    "    bins=bins[:-1]\n",
    "    y_hat= sm.nonparametric.lowess(exog=bins, endog=count, frac=0.3)[:, 1] #\n",
    "    \n",
    "    \n",
    "    #filter\n",
    "    \n",
    "    ISIth=peak(y_hat, bins, th)\n",
    "    \n",
    "    ##print(ISIth, 'ISIth')\n",
    "    \n",
    "    if ISIth!=None:\n",
    "        \n",
    "        ##print('checking this')\n",
    "        \n",
    "        \n",
    "        \n",
    "        extendFlag=1\n",
    "        maxISI1 = np.log10(th)\n",
    "        maxISI2=ISIth\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "        if ISIth<np.log10(th):\n",
    "            \n",
    "            ##print('Case 1, Peak based')\n",
    "\n",
    "            maxISI1=ISIth\n",
    "\n",
    "            extendFlag=0\n",
    "\n",
    "            cross_ids=np.where(ISI<maxISI1)[0] \n",
    "            ##print(len(cross_ids))###(threshold/8))[0]\n",
    "\n",
    "            diffcross_ids=np.diff(cross_ids).tolist()\n",
    "\n",
    "            for i in range(len(diffcross_ids)):\n",
    "\n",
    "                if diffcross_ids[i] < 2:\n",
    "\n",
    "                    bind=bind+cross_ids.tolist()[i:i+2]\n",
    "\n",
    "                else:\n",
    "\n",
    "                    if len(bind)>1:\n",
    "                        Bursts.append(sp[min(bind):(max(bind)+2)].tolist())\n",
    "\n",
    "                    bind=[]\n",
    "                    continue\n",
    "\n",
    "        else:\n",
    "            \n",
    "            ##print('Case 2' , 'long peak')\n",
    "\n",
    "            cross_ids=np.where(ISI<maxISI1)[0] \n",
    "            ###print(len(cross_ids))###(threshold/8))[0]\n",
    "\n",
    "            diffcross_ids=np.diff(cross_ids).tolist()\n",
    "\n",
    "            for i in range(len(diffcross_ids)):\n",
    "\n",
    "                if diffcross_ids[i] < 2:\n",
    "\n",
    "                    bind=bind+cross_ids.tolist()[i:i+2]\n",
    "\n",
    "                else:\n",
    "\n",
    "                    if len(bind)>5:\n",
    "\n",
    "                        right=bind[-1]\n",
    "                        left=bind[0]\n",
    "\n",
    "\n",
    "                        for index in range(left, 0, -1):\n",
    "                            if ISI[index]<maxISI1:\n",
    "                                bind=[index]+bind\n",
    "                            else:\n",
    "                                break\n",
    "                        for index in range(right, len(ISI), 1):\n",
    "                            if ISI[index]<maxISI2:\n",
    "                                bind=bind+[index]\n",
    "                            else:\n",
    "                                break\n",
    "\n",
    "                        Bursts.append(sp[min(bind):(max(bind)+2)].tolist())\n",
    "\n",
    "                        bind=[]\n",
    "\n",
    "                        continue\n",
    "\n",
    "                    else:\n",
    "                        bind=[]\n",
    "                        continue\n",
    "\n",
    "\n",
    "                   \n",
    "        ##print(len(Bursts))\n",
    "\n",
    "        if extendFlag==1:\n",
    "\n",
    "            if len(Bursts) > 0:       \n",
    "                merge.append(Bursts[0])\n",
    "                \n",
    "               \n",
    "\n",
    "                for B in Bursts[1:]:\n",
    "\n",
    "                    if B[0]-merge[-1][-1] < maxISI2: #merge burst that are not separated with void///update///\n",
    "                        merge[-1].extend(B)\n",
    "                        \n",
    "                    else:\n",
    "                        merge.append(B)\n",
    "                       \n",
    "                        \n",
    "                        \n",
    "            Bursts=merge\n",
    " \n",
    "    else:\n",
    "        ##print('Case 0, no peak')\n",
    "        maxISI1=np.log10(th)\n",
    "\n",
    "        cross_ids=np.where(ISI<maxISI1)[0] \n",
    "        ###print(len(cross_ids))###(threshold/8))[0]\n",
    "\n",
    "        diffcross_ids=np.diff(cross_ids).tolist()\n",
    "\n",
    "        for i in range(len(diffcross_ids)):\n",
    "\n",
    "            if diffcross_ids[i] < 2:\n",
    "\n",
    "                bind=bind+cross_ids.tolist()[i:i+2]\n",
    "\n",
    "            else:\n",
    "\n",
    "                if len(bind)>5:\n",
    "                    Bursts.append(sp[min(bind):(max(bind)+2)].tolist())\n",
    "\n",
    "                bind=[]\n",
    "                continue\n",
    "\n",
    "        \n",
    "                \n",
    "    return (Bursts, np.ones(len(Bursts)))\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def MaxInterval(sp, f, startISI, endISI, minIBI, minNSpikes):\n",
    "    \n",
    "    \"\"\"Function to  detect burst-like spike trains\"\"\"\n",
    "    \n",
    "   \n",
    "    \n",
    "    Bursts=[]\n",
    "    \n",
    "    bind=[]\n",
    "    merge=[]\n",
    "    \n",
    "    ISI=np.diff(sp)\n",
    "    ##print(min(ISI), 'minISI')\n",
    "    \n",
    "    start_indexes=np.where(ISI<startISI)[0]\n",
    "    ##print(len(start_indexes), 'lenstarts')\n",
    "    end_index=-1\n",
    "    \n",
    "    for start_index in start_indexes:\n",
    "        \n",
    "        bind=[]\n",
    "        \n",
    "        ###print(start_index, 'start_index')\n",
    "        \n",
    "        if start_index>end_index:\n",
    "            \n",
    "            ###print('here')\n",
    "        \n",
    "            for i in range(start_index, len(ISI)):\n",
    "                \n",
    "                ###print(i, ISI[i], 'isi')\n",
    "                if ISI[i]<endISI:\n",
    "                    bind.append(i)\n",
    "                else:\n",
    "                    end_index=i\n",
    "                    \n",
    "                    if (len(bind)>=minNSpikes) and (sp[max(bind)+2]-sp[min(bind)])>=10000:\n",
    "                        \n",
    "                        Bursts.append(sp[min(bind):(max(bind)+2)].tolist())\n",
    "                        bind=[]\n",
    "                        \n",
    "                    bind=[]\n",
    "                    break\n",
    "                    \n",
    "        else:\n",
    "            continue\n",
    "            \n",
    "     \n",
    "                    \n",
    "    ##print(len(Bursts))        \n",
    "    if len(Bursts) > 0:       \n",
    "        merge.append(Bursts[0])\n",
    "        \n",
    "      \n",
    "\n",
    "        for B in Bursts[1:]:\n",
    "            \n",
    "            if B[0]-merge[-1][-1] < minIBI: #merge burst that are not separated with minIBI\n",
    "                merge[-1].extend(B)\n",
    "                \n",
    "               \n",
    "\n",
    "            else:\n",
    "                merge.append(B)\n",
    "                \n",
    "                \n",
    "    return (merge, np.ones(len(merge)))\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def state_change(surprises, sp):\n",
    "    \n",
    "    #is surprise positive value \n",
    "    \n",
    "    ##if change is more than 50% new state? \n",
    "    ##threshold for 3std\n",
    "    \n",
    "    surprises=surprises[1:]\n",
    "    \n",
    "    ##print(len(surprises), 'lengthofsurprise')\n",
    "    sp=sp[2:]\n",
    "    \n",
    "    ##print(len(sp), 'lengthofspikes')\n",
    "    \n",
    "    threshold=np.std(surprises)*3\n",
    "    \n",
    "    highstatetrans=(surprises>threshold).astype('int')\n",
    "    \n",
    "    lowstatetrans=(surprises<threshold).astype('int')\n",
    "    \n",
    "    ##print(highstatetrans, np.diff(highstatetrans), 'initinnf')\n",
    "    \n",
    "    highstatest=np.where(np.diff(highstatetrans)==1)[0]\n",
    "    highstateend=np.where(np.diff(highstatetrans)==-1)[0]\n",
    "    \n",
    "    ##print(highstatest, highstateend, '1ns,-1ns')\n",
    "    \n",
    "    hst=[]\n",
    "    hend=[]\n",
    "    \n",
    "    if len(highstatest)>0 and len(highstateend)>0:\n",
    "        \n",
    "        if highstateend[0]<highstatest[0]:\n",
    "            \n",
    "            hst.append(0)\n",
    "            hend.append(highstateend[0])\n",
    "    \n",
    "    if len(highstatest)>0:\n",
    "    \n",
    "        for stindex in highstatest:\n",
    "\n",
    "\n",
    "\n",
    "            pair=-1\n",
    "            \n",
    "            \n",
    "\n",
    "\n",
    "            if len(highstateend)>0:\n",
    "                \n",
    "                for endindex in highstateend:\n",
    "                    if endindex>stindex: ###if ends when started\n",
    "\n",
    "                        pair=endindex\n",
    "\n",
    "\n",
    "                        hst.append(stindex)\n",
    "                        hend.append(endindex)\n",
    "\n",
    "                        break\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            if pair==-1:  #if start does not end\n",
    "\n",
    "                hst.append(stindex)\n",
    "                hend.append(len(surprises)-1)\n",
    "    else:\n",
    "        if len(highstateend)>0:\n",
    "            \n",
    "            hst.append(0)\n",
    "            hend.append(highstateend[0])\n",
    "    \n",
    "            \n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "        \n",
    "        \n",
    "    ##print(hst, hend, 'hst, hend')\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "        \n",
    "    hstlow=[0]+hend\n",
    "    \n",
    "    \n",
    "    hendlow=hst+[len(surprises)-1]\n",
    "                \n",
    "                \n",
    "    ##print(hstlow, hendlow, 'lwosfg')\n",
    "    \n",
    "    highspikesindex=[np.arange(hst[ind], hend[ind]+1).tolist() for ind in range(len(hst))]\n",
    "    \n",
    "    lowspikesindex=[np.arange(hstlow[ind], hendlow[ind]+1).tolist() for ind in range(len(hstlow))]\n",
    "    \n",
    "    highspikes=[sp[hst[ind]:hend[ind]+1] for ind in range(len(hst))]\n",
    "    \n",
    "    lowspikes=[sp[hstlow[ind]:hendlow[ind]+1] for ind in range(len(hstlow))]\n",
    "    \n",
    "    y_hat= sm.nonparametric.lowess(exog=np.arange(0, len(surprises)), endog=surprises, frac=0.1)[:, 1]\n",
    "    \n",
    "    #plt.plot(surprises, color='blue')\n",
    "    \n",
    "    \n",
    "    \n",
    "    #peaks_indexes=find_peak(y_hat)\n",
    "    \n",
    "    \n",
    "    cf = changefinder.ChangeFinder()\n",
    "    scores = [cf.update(p) for p in surprises]\n",
    "    plt.plot(scores, color='red')\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    return highspikesindex, lowspikesindex, threshold, highspikes, lowspikes\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def dynsurprise(sp, ISI, f):\n",
    "    \n",
    "    \n",
    "    SpikeGroups=[]\n",
    "    BigSurprise=[]\n",
    "    test_bind=[0, 1]\n",
    "    \n",
    "    for index in range(0, len(sp)-1):\n",
    "        \n",
    "        \n",
    "        test_bind[1]=index\n",
    "        \n",
    "        if test_bind[1]-test_bind[0]>100:\n",
    "            \n",
    "            workingsp=sp[test_bind[0]:test_bind[1]+1]\n",
    "            \n",
    "            highr, lowr, th, highspikes, lowspikes=state_change(BigSurprise, workingsp)\n",
    "            \n",
    "            high=[i for el in highr for i in el]\n",
    "            low=[i for el in lowr for i in el]\n",
    "            \n",
    "            SpikeGroups.extend(highspikes)\n",
    "            SpikeGroups.extend(lowspikes)\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            test_bind[0]=index\n",
    "            \n",
    "          \n",
    "            \n",
    "            \n",
    "            \n",
    "            plt.figure(figsize=(8, 10))\n",
    "    \n",
    "            plt.plot(BigSurprise[1:])\n",
    "            y = np.interp(high, np.arange(0, len(BigSurprise[1:]), 1), BigSurprise[1:])\n",
    "            w= np.interp(low, np.arange(0, len(BigSurprise[1:]), 1), BigSurprise[1:])\n",
    "            \n",
    "            plt.axhline(y=th)\n",
    "            plt.plot(high, y, ls=\"\", marker=\"*\", ms=15,  color=\"crimson\")\n",
    "            plt.plot(low, w, ls=\"\", marker=\"*\", ms=15,  color=\"blue\")\n",
    "            \n",
    "            \n",
    "    \n",
    "            plt.show()\n",
    "        \n",
    "            BigSurprise=[]\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        surpr=Surprise(sp, test_bind, ISI, f)\n",
    "        \n",
    "        BigSurprise.append(surpr)\n",
    "        \n",
    "    \n",
    "    plt.figure(figsize=(8, 10))\n",
    "    \n",
    "    plt.plot(BigSurprise)\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    return surpr\n",
    "    \n",
    "    \n",
    "    \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "###reattendng poisson \n",
    "##what does relatively long interval mean. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def PoissonSurprisetrue(sp, surpriseth, f):\n",
    "    \n",
    "    \"\"\"Function to  detect burst-like spike trains\"\"\"\n",
    "    \n",
    "    Bursts=[]\n",
    "    \n",
    "    #container\n",
    "   \n",
    "   \n",
    "    sp=np.sort(sp) #sorted spikes\n",
    "    \n",
    "    ISI=np.diff(sp) #ISIs \n",
    "    ISImean=np.mean(ISI)\n",
    "    ISIhalfmean=ISImean/2\n",
    "    ISIdoublemean=2*ISImean\n",
    "    test_surprise=[]\n",
    "    \n",
    "    \n",
    "    #f=len(sp)/((sp[-1]-sp[0])/1000000) #N/seconds###frequency \n",
    "    \n",
    "    #esimench=dynsurprise(sp, ISI, f)\n",
    "    \n",
    "    \n",
    "    \n",
    "    ###print(f, 'Average FIring rate')\n",
    "    start_indexes=np.where(ISI<ISIhalfmean)[0]\n",
    "    \n",
    "    end_index=-1\n",
    "    \n",
    "    for i in range(len(start_indexes)-3):\n",
    "        \n",
    "        if  start_indexes[i]>end_index:\n",
    "            bind=[-1, -1]\n",
    "\n",
    "            if all(np.diff(start_indexes[i:i+3])==1):\n",
    "\n",
    "                bind[0]=start_indexes[i]\n",
    "                bind[1]=start_indexes[i+2] #or 4\n",
    "                \n",
    "                \n",
    "                \n",
    "\n",
    "                p0=Surprise(sp, bind, ISI, f)\n",
    "                \n",
    "                \n",
    "                fwd_failed=0\n",
    "                \n",
    "                test_bind=bind\n",
    "\n",
    "                for j in range(start_indexes[i+2]+1, len(ISI)):\n",
    "                    \n",
    "                    ###stop adding if long interval and (or?) already 10 forward spikes failed, or\n",
    "\n",
    "                    if ISI[j]<ISIdoublemean and fwd_failed<3:\n",
    "                        test_bind[1]=j\n",
    "                        \n",
    "\n",
    "                        \n",
    "                        p=Surprise(sp, test_bind, ISI, f)\n",
    "                        \n",
    "                       \n",
    "                        \n",
    "                        #if extension maximizes the surprise, extend\n",
    "\n",
    "                        if p>p0:\n",
    "                            bind[1]=j\n",
    "                            p0=p\n",
    "                            \n",
    "                        #if extension is not maximizing, bursts right index is defined\n",
    "                        else:  \n",
    "                            fwd_failed=fwd_failed+1\n",
    "                            end_index=bind[1]\n",
    "                            \n",
    "                          \n",
    "                            #search for left index\n",
    "                    else:\n",
    "                        end_index=bind[1]\n",
    "                        for i in range(bind[0]+1, bind[1]):\n",
    "                            \n",
    "                            p=Surprise(sp, [i, bind[1]], ISI, f)\n",
    "                            #if removing from the start increases surprise, remove \n",
    "                            if p>p0:\n",
    "                                bind[0]=i\n",
    "                                p0=p\n",
    "                            #else left is defined\n",
    "                            else:\n",
    "                                #if defined burst is higher than the given threshold\n",
    "                                if p0>surpriseth:\n",
    "                                    test_surprise.append(p0)\n",
    "                                    \n",
    "                                    Bursts.append(sp[bind[0]:bind[1]+1].tolist())\n",
    "\n",
    "                                    bind=[-1, -1]\n",
    "                                else:\n",
    "                                    bind=[-1, -1]\n",
    "\n",
    "                                break\n",
    "                        break \n",
    "                          \n",
    "    return (Bursts, test_surprise)\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def PoissonSurprise_test0(sp, surpriseth):\n",
    "    \n",
    "    \"\"\"Function to  detect burst-like spike trains\"\"\"\n",
    "    \n",
    "    Bursts=[] #container\n",
    "   \n",
    "   \n",
    "    sp=np.sort(sp) #sorted spikes\n",
    "    plots=0\n",
    "    ISI=np.diff(sp) #ISIs \n",
    "    ISImean=np.mean(ISI)\n",
    "    ISIhalfmean=ISImean/2\n",
    "    ISIdoublemean=2*ISImean\n",
    "    \n",
    "    test_surprise=[]\n",
    "    \n",
    "    test_Nofspikes=[]\n",
    "    \n",
    "    test_spikingrate=[]\n",
    "    \n",
    "    figevent, axesevent=plt.subplots(1, 1, figsize=(30, 6))\n",
    "    axesevent.eventplot(sp, colors='grey', linewidths=0.8, alpha=0.6, linelengths=0.8)\n",
    "    cm_subsection = np.arange(0, 55, 5)\n",
    "    from  matplotlib.colors import Normalize\n",
    "    cm_normed=Normalize(vmin=0, vmax=50, clip=False)\n",
    "    from matplotlib import cm\n",
    "    \n",
    "   \n",
    "    colors=[ cm.jet(cm_normed(x)) for x in cm_subsection ]\n",
    "    \n",
    "    ##print(cm_normed(x)) for x in cm_subsection]\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    f=len(sp)/((sp[-1]-sp[0])/1000000) #N/seconds\n",
    "    \n",
    "    esimench=dynsurprise(sp, ISI, f)\n",
    "    \n",
    "    ###print(f, 'Average FIring rate')\n",
    "    start_indexes=np.where(ISI<ISIhalfmean)[0]\n",
    "    \n",
    "    end_index=-1\n",
    "    \n",
    "    for i in range(len(start_indexes)-3):\n",
    "        \n",
    "        if  start_indexes[i]>end_index:\n",
    "            bind=[-1, -1]\n",
    "\n",
    "            if all(np.diff(start_indexes[i:i+4])==1):\n",
    "\n",
    "                bind[0]=start_indexes[i]\n",
    "                bind[1]=start_indexes[i+3] #or 4\n",
    "                \n",
    "\n",
    "                p0=Surprise(sp, bind, ISI, f)\n",
    "                \n",
    "                \n",
    "                fwd_failed=0\n",
    "                \n",
    "                test_bind=bind\n",
    "\n",
    "                for j in range(start_indexes[i+3]+1, len(ISI)):\n",
    "                    \n",
    "                   \n",
    "\n",
    "                    if ISI[j]<ISIdoublemean and fwd_failed<10:\n",
    "                        test_bind[1]=j\n",
    "                        \n",
    "\n",
    "                        \n",
    "                        p=Surprise(sp, test_bind, ISI, f)\n",
    "                        \n",
    "                       \n",
    "                        \n",
    "                        #if extension maximizes the surprise, extend\n",
    "\n",
    "                        if p>p0:\n",
    "                            bind[1]=j\n",
    "                            p0=p\n",
    "                            \n",
    "                        #if extension is not maximizing, bursts right index is defined\n",
    "                        elif p==p0:  \n",
    "                            fwd_failed=fwd_failed+1\n",
    "                            end_index=bind[1]\n",
    "                        else:\n",
    "                            fwd_failed=fwd_failed+10\n",
    "                            end_index=bind[1]\n",
    "                            \n",
    "                            \n",
    "                          \n",
    "                            #search for left index\n",
    "                    else:\n",
    "                        end_index=bind[1]\n",
    "                        for i in range(bind[0]+1, bind[1]):\n",
    "                            p=Surprise(sp, [i, bind[1]], ISI, f)\n",
    "                            #if removing from the start increases surprise, remove \n",
    "                            if p>p0:\n",
    "                                bind[0]=i\n",
    "                                p0=p\n",
    "                            #else left is defined\n",
    "                            else:\n",
    "                                #if defined burst is higher than the given threshold\n",
    "                                if p0>surpriseth:\n",
    "                                    \n",
    "                                    test_surprise.append(p0)\n",
    "                                    test_Nofspikes.append(len(sp[bind[0]:bind[1]+1]))\n",
    "                                    test_spikingrate.append(len(sp[bind[0]:bind[1]+1])/((sp[bind[0]:bind[1]+1][-1])-\n",
    "                                                            (sp[bind[0]:bind[1]+1][0])/1000000))\n",
    "                                    ###print(p, p0, 'p, p0')\n",
    "                                    \n",
    "                                    \n",
    "                                    if (p0>=0) and (p0 <=50):\n",
    "                                        \n",
    "                                        color_index=int(p0//5)\n",
    "                                        \n",
    "                                        color=colors[color_index]\n",
    "                                        \n",
    "                                        \n",
    "                                       \n",
    "                                        \n",
    "                                        axesevent.eventplot(sp[bind[0]:bind[1]+1].tolist(), colors=color, linewidths=0.8, linelengths=0.8)\n",
    "                                        plt.annotate(str(p0), xy=(sp[bind[0]:bind[1]+1].tolist()[0], 1.5), xytext=(sp[bind[0]:bind[1]+1].tolist()[0], 1.5))\n",
    "                                    \n",
    "                                    \n",
    "                                   \n",
    "                                        \n",
    "                                        \n",
    "                                    Bursts.append(sp[bind[0]:bind[1]+1].tolist())\n",
    "\n",
    "                                    bind=[-1, -1]\n",
    "                                else:\n",
    "                                    bind=[-1, -1]\n",
    "\n",
    "                                break\n",
    "                        break \n",
    "    \n",
    "    \n",
    "    from  matplotlib.colors import ListedColormap\n",
    "    \n",
    "    \n",
    "    \n",
    "    cmap =ListedColormap(colors)\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    plt.colorbar(cm.ScalarMappable(norm=cm_normed, cmap=cmap), ax=axesevent)#, ticks=np.arange(0, 55, 5).tolist())\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "    plot_burst(test_surprise, test_Nofspikes, test_spikingrate)\n",
    "\n",
    "           \n",
    "\n",
    "    return (Bursts, test_surprise)\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def return_bokeh_colormap(name):\n",
    "    cm = plt.cm.get_cmap(name)\n",
    "    colormap = [rgb_to_hex(tuple((np.array(cm(x))*255).astype('int'))) for x in range(0,cm.N)]\n",
    "    return colormap\n",
    "def rgb_to_hex(rgb):\n",
    "    return '#%02x%02x%02x' % rgb[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def PoissonSurprise(sp, f, surpriseth):\n",
    "    \n",
    "    \n",
    "    ##print(surpriseth, 'supriseth')\n",
    "    \n",
    "    \"\"\"Function to  detect burst-like spike trains\"\"\"\n",
    "    \n",
    "    Bursts=[] #container\n",
    "   \n",
    "   \n",
    "    sp=np.sort(sp) #sorted spikes\n",
    "    plots=0\n",
    "    ISI=np.diff(sp) #ISIs \n",
    "    ISImean=np.mean(ISI)\n",
    "    ISIhalfmean=ISImean/2\n",
    "    ISIdoublemean=2*ISImean\n",
    "    \n",
    "    test_surprise=[]\n",
    "    \n",
    "    test_Nofspikes=[]\n",
    "    \n",
    "    test_spikingrate=[]\n",
    "    \n",
    "    #figevent, axesevent=plt.subplots(1, 1, figsize=(30, 6))\n",
    "    #axesevent.eventplot(sp, colors='grey', linewidths=0.8, alpha=0.6, linelengths=0.8)\n",
    "   \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #f=len(sp)/((sp[-1]-sp[0])/1000000) #N/seconds\n",
    "    \n",
    "    #esimench=dynsurprise(sp, ISI, f)\n",
    "    \n",
    "    ###print(f, 'Average FIring rate')\n",
    "    start_indexes=np.where(ISI<ISIhalfmean)[0] ##strict threshold\n",
    "    \n",
    "    end_index=-1\n",
    "    \n",
    "    for i in range(len(start_indexes)-3):\n",
    "        \n",
    "        if  start_indexes[i]>end_index:\n",
    "            bind=[-1, -1]\n",
    "\n",
    "            if all(np.diff(start_indexes[i:i+3])==1):\n",
    "\n",
    "                bind[0]=start_indexes[i]\n",
    "                bind[1]=start_indexes[i+2] #or 4\n",
    "                \n",
    "\n",
    "                p0=Surprise(sp, bind, ISI, f)\n",
    "                \n",
    "                \n",
    "                fwd_failed=0\n",
    "                \n",
    "                test_bind=bind\n",
    "\n",
    "                for j in range(start_indexes[i+2]+1, len(ISI)):\n",
    "                    \n",
    "                   \n",
    "\n",
    "                    if ISI[j]<ISIdoublemean and fwd_failed<10:\n",
    "                        test_bind[1]=j\n",
    "                        \n",
    "\n",
    "                        \n",
    "                        p=Surprise(sp, test_bind, ISI, f)\n",
    "                        \n",
    "                       \n",
    "                        \n",
    "                        #if extension maximizes the surprise, extend\n",
    "\n",
    "                        if p>=p0:\n",
    "                            bind[1]=j\n",
    "                            p0=p\n",
    "                            \n",
    "                        #if extension is not maximizing, bursts right index is defined\n",
    "                        \n",
    "                            \n",
    "                       \n",
    "                        else:\n",
    "                            fwd_failed=fwd_failed+3\n",
    "                            end_index=bind[1]\n",
    "                            \n",
    "                            \n",
    "                          \n",
    "                            #search for left index\n",
    "                    else:\n",
    "                        end_index=bind[1]\n",
    "                        \n",
    "                        \n",
    "                        for i in range(bind[0]+1, bind[1]):\n",
    "                            \n",
    "                          \n",
    "                            \n",
    "                            p=Surprise(sp, [i, bind[1]], ISI, f)\n",
    "                            #if removing from the start only increases surprise, remove \n",
    "                            if p>1.5*p0:\n",
    "                                bind[0]=i\n",
    "                                p0=p\n",
    "                            #else left is defined\n",
    "                            else:\n",
    "                                #if defined burst is higher than the given threshold\n",
    "                                if p0>surpriseth:\n",
    "                                    \n",
    "                                    \n",
    "                                    \n",
    "                                    test_surprise.append(p0)\n",
    "                                    test_Nofspikes.append(len(sp[bind[0]:bind[1]+1]))\n",
    "                                    test_spikingrate.append(len(sp[bind[0]:bind[1]+1])/((sp[bind[0]:bind[1]+1][-1])-\n",
    "                                                            (sp[bind[0]:bind[1]+1][0])/1000000))\n",
    "                                    ###print(p, p0, 'p, p0')\n",
    "                                    \n",
    "                                   \n",
    "\n",
    "                                    #axesevent.eventplot(sp[bind[0]:bind[1]+1].tolist(), colors=color, linewidths=0.8, linelengths=0.8)\n",
    "                                    #plt.annotate(str(p0), xy=(sp[bind[0]:bind[1]+1].tolist()[0], 1.5), xytext=(sp[bind[0]:bind[1]+1].tolist()[0], 1.5))\n",
    "                                    \n",
    "                                    \n",
    "                                   \n",
    "                                        \n",
    "                                        \n",
    "                                    Bursts.append(sp[bind[0]:bind[1]+1].tolist())\n",
    "\n",
    "                                    bind=[-1, -1]\n",
    "                                else:\n",
    "                                    bind=[-1, -1]\n",
    "\n",
    "                                break\n",
    "                        break \n",
    "    \n",
    "    \n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "    #plot_burst(test_surprise, test_Nofspikes, test_spikingrate)\n",
    "\n",
    "           \n",
    "\n",
    "    return (Bursts, test_surprise)\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plot_burst(surpise, nofspikes, rateofspikes):\n",
    "    \n",
    "    figs, axes=plt.subplots(3, 1, figsize=(8, 10))\n",
    "    \n",
    "    count, bins=np.histogram(surpise, np.arange(0, 50, 5))\n",
    "    \n",
    "    axes[0].hist(count, bins=bins[:-1], histtype='step')\n",
    "    axes[0].set_title('Histrogram of Surprises')\n",
    "    axes[0].set_xlabel('Surprise')\n",
    "    axes[0].set_ylabel('Number of Trains')\n",
    "    \n",
    "    axes[1].scatter(surpise, nofspikes)\n",
    "    axes[1].set_title('Scatter of surprisea and spikes ')\n",
    "    axes[1].set_xlabel('Surprise')\n",
    "    axes[1].set_ylabel('Number of Spikes')\n",
    "    \n",
    "     \n",
    "    axes[2].scatter(surpise, rateofspikes)\n",
    "    axes[2].set_title('Scatter of surprisea and spike rate ')\n",
    "    axes[2].set_xlabel('Surprise')\n",
    "    axes[2].set_ylabel('Spiking rate')\n",
    "    figs.tight_layout()\n",
    "\n",
    "    \n",
    "   \n",
    "    \n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "        \n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#modify poisson ina way that you don't remove from the start\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import poisson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "repeated the process until either a relatively long\n",
    "interval was encountered or inclusion of one or\n",
    "more (up to 10) additional spikes failed to increase\n",
    "the Poisson surprise. (The length of such a relatively\n",
    "long interval had been chosen to be twice the\n",
    "buffer-wide average.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def Surprise(sp, test_bind, ISI, f, external=False):\n",
    "    \n",
    "    \n",
    "    #sp is a list of event times in microseconds\n",
    "    \n",
    "   #indexes of events in list\n",
    "\n",
    "\n",
    "\n",
    "    if external==False:\n",
    "\n",
    "        T=(sp[(test_bind[1]+1)]-sp[test_bind[0]])/1000000\n",
    "\n",
    "        ###print(T, 'Interval')\n",
    "        ###print((test_bind[1]-test_bind[0])+1, 'lentoolarge?')\n",
    "\n",
    "        rng=(test_bind[1]-test_bind[0])\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        T=(test_bind[-1]-test_bind[0])/1000000\n",
    "        rng=len(test_bind)\n",
    "        \n",
    "        \n",
    "    try:\n",
    "        p=poisson.sf(rng, f*T)#cumulative=sum([((f*T)**i)/np.math.factorial(i) for i in range(rng+1)])\n",
    "        \n",
    "        #p=1-((np.exp(-(f*T)))*cumulative)\n",
    "    \n",
    "    except:\n",
    "        ##print('overflow')\n",
    "        p=poisson.sf(rng, f*T)\n",
    "        \n",
    "\n",
    "\n",
    "    #if (p<0) or (p>100000000):\n",
    "        \n",
    "        ##print(p, 'probabilty')\n",
    "    \n",
    "\n",
    "    surprise=-np.log2(p)\n",
    "    \n",
    "    ###print(surprise, 'suprise')\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    return (surprise)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f=5\n",
    "n=6\n",
    "T=0.4\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cumulative=sum([((f*T)**i)/np.math.factorial(i) for i in range(n+1)])\n",
    "\n",
    "\n",
    "p=1-((np.exp(-(f*T)))*cumulative)\n",
    "\n",
    "##print(p, -np.log10(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "###testing, calibrating Poisson Surprise\n",
    "\n",
    "###PLot Surprise to Number of bursts\n",
    "### Plot Surpise to Number of spikes in burst\n",
    "### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#parameterssets\n",
    "\n",
    "plogisi={'set1':[150000], 'set2':[100000], 'set3': [200000]}\n",
    "pmaxinterval={'set2': [150000, 250000, 2500000, 3], \n",
    "            }\n",
    "psurprise={'set1':[7]}\n",
    "\n",
    "params_set={}\n",
    "\n",
    "params_set['logisi']=plogisi\n",
    "params_set['poisson']=psurprise\n",
    "params_set['maxinterval']=pmaxinterval\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#parameterssets\n",
    "\n",
    "plogisi={'set1':[150000]}\n",
    "pmaxinterval={'set1':[100000, 150000, 200000, 250000, 3]}\n",
    "psurprise={'set1':[10]}\n",
    "\n",
    "params_set={}\n",
    "\n",
    "params_set['logisi']=plogisi\n",
    "params_set['poisson']=psurprise\n",
    "params_set['maxinterval']=pmaxinterval\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def burst_stat(spikes, methods, to, file, stamp, params_set):\n",
    "    \n",
    "    \n",
    "    \n",
    "    \"\"\"Function to extract burst parameters and write in table, \n",
    "    Inputs\n",
    "    spikes: spikes dataframe, from single experiment\n",
    "    methods: is list methods, possible- ['logisi', 'poisson', 'maxinterval']\n",
    "    \n",
    "    Outputs\n",
    "    \n",
    "    Write files in a folder, bursts per experment\"\"\"\n",
    "    \n",
    "    \n",
    "    #spikes['Dose Label']=spikes['Dose Label'].apply(lambda x : 0 if x=='Control' else int(x)) #int\n",
    "    \n",
    "\n",
    "    df=pd.DataFrame()\n",
    "    \n",
    "    \n",
    "    chids=np.unique(spikes['Channel ID'].values)\n",
    "    \n",
    "    compound=np.unique(spikes['Compound ID'])[0] \n",
    "    #Compound ID in later versions. \n",
    "    experiment=np.unique(spikes['Experiment'])[0]\n",
    "    \n",
    "   \n",
    "   \n",
    "    \n",
    "    for method in methods:\n",
    "        \n",
    "        \n",
    "        df=pd.DataFrame()\n",
    "        \n",
    "        \n",
    "        if method=='logisi':\n",
    "            \n",
    "            \n",
    "            \n",
    "            for setn in list(params_set[method].keys()):\n",
    "            \n",
    "                #args=[150000]\n",
    "\n",
    "                args=params_set[method][setn]\n",
    "\n",
    "                dataset=create_dataset(spikes, chids, compound, experiment, df, stamp, LogISI, method, False,  *args)\n",
    "                dataset[1:].to_csv(to+'/'+file[:-10]+'LogISIBursts'+'.csv')  \n",
    "        if method=='poisson':\n",
    "            \n",
    "            #args=[5]\n",
    "            \n",
    "            for setn in list(params_set[method].keys()):\n",
    "            \n",
    "                #args=[150000]\n",
    "\n",
    "                args=params_set[method][setn]\n",
    "                \n",
    "                #print(method, args,  'method, args', df.head())\n",
    "            \n",
    "                dataset=create_dataset(spikes, chids, compound, experiment, df, stamp, PoissonSurprise, method, False,  *args)\n",
    "                dataset[1:].to_csv(to+'/'+file[:-10]+'PoissonBursts'+'.csv') \n",
    "            \n",
    "        if method=='maxinterval':\n",
    "            \n",
    "            #args=[200000, 300000, 200000, 3]\n",
    "            for setn in list(params_set[method].keys()):\n",
    "                \n",
    "                #print(method, args,  'method, args', df.head())\n",
    "            \n",
    "                #args=[150000]\n",
    "\n",
    "                args=params_set[method][setn]\n",
    "            \n",
    "            \n",
    "            \n",
    "                dataset=create_dataset(spikes, chids, compound, experiment, df, stamp, MaxInterval, method, False,  *args)\n",
    "                dataset[1:].to_csv(to+'/'+file[:-10]+'MaxIntervalBursts'+setn+'.csv') \n",
    "\n",
    "            \n",
    "            \n",
    "    return df          \n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def create_dataset(spikes, channels, compound, experiment, df, stamp, function, method, plot,  *args):\n",
    "    \n",
    "    '''Helper function to create a dataset'''\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "    ##print(method)\n",
    "   \n",
    "    wells=np.unique(spikes['Well ID'].values)\n",
    "    \n",
    "    ps=[figure(width=800, height=500, title=method+str(wells[r])+experiment) for r in range(len(wells))]\n",
    "    \n",
    "    \n",
    "                           \n",
    "    for indx, chid in enumerate(channels):\n",
    "        \n",
    "        \n",
    "        colors=return_bokeh_colormap('viridis')\n",
    "        colors_range=np.linspace(0, 200, 256)\n",
    "        div=np.diff(colors_range)[0]\n",
    "        color_mapper = LinearColorMapper(palette = colors, low = 0, high=200)\n",
    "        \n",
    "    \n",
    "        \n",
    "        dlabels=np.unique(spikes[spikes['Channel ID']==chid]['Dose Label'].values)\n",
    "        #print(spikes[spikes['Channel ID']==chid].iloc[0, 3:7])\n",
    "        \n",
    "        #print(dlabels, 'dlabels')\n",
    "        for dlabel in dlabels:\n",
    "            \n",
    "            st, end=segment(stamp, dlabel, 'Burst')\n",
    "            \n",
    "            length=end-st\n",
    "            \n",
    "            #print(length, 'length')\n",
    "\n",
    "\n",
    "\n",
    "            #print(compound, 'Compound')\n",
    "\n",
    "            #print(dlabel, 'Label')\n",
    "\n",
    "            #print(chid, 'Channel')\n",
    "\n",
    "            spiketrain=spikes[(spikes['Channel ID']==chid) & (spikes['Dose Label']==dlabel)]['Timestamp [µs]'].sort_values(ascending=True).values\n",
    "            wiid=spikes[(spikes['Channel ID']==chid) & (spikes['Dose Label']==dlabel)]['Well ID'].values[0]\n",
    "\n",
    "            chlab=spikes[(spikes['Channel ID']==chid) & (spikes['Dose Label']==dlabel)]['Channel Label'].values[0]\n",
    "\n",
    "            pind=np.where(wells==wiid)[0][0]\n",
    "            ##print(pind, wells, wiid)\n",
    "            g=spikes[spikes['Channel ID']==chid]['Well ID'].values[0]\n",
    "            ##print(g, 'Well ID')#Well ID\n",
    "\n",
    "            p1=ps[pind]\n",
    "            \n",
    "            p1.rect(x=spiketrain,  y=np.ones(len(spiketrain))*chlab, width=2000, height=0.5, fill_color=\"grey\", line_color=\"blue\")\n",
    "\n",
    "            f=len(spiketrain)/(length/1000000)\n",
    "            \n",
    "            bursts_outputs=function(spiketrain, f, *args)\n",
    "            \n",
    "\n",
    "            bursts=bursts_outputs[0]\n",
    "            \n",
    "            ##print(bursts, 'bursts')\n",
    "\n",
    "            burstspikes=sum([len(bur) for bur in bursts])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "            ISI=np.diff(spiketrain)\n",
    "\n",
    "\n",
    "            for burst in bursts:\n",
    "                \n",
    "                \n",
    "\n",
    "                if len(burst)>0:\n",
    "                    \n",
    "                    #print('we have burs')\n",
    "\n",
    "                    s=Surprise(spiketrain, burst, ISI, f, external=True)\n",
    "                    \n",
    "                    \n",
    "                    if plot==True:\n",
    "                        \n",
    "                        #print('plot is true', burst[0]+((burst[-1]-burst[0])/2), spiketrain[0])\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                   \n",
    "                        \n",
    "                        #color_index=int(s//div)\n",
    "\n",
    "                        #color=colors[color_index]\n",
    "\n",
    "\n",
    "                        p1.rect(x=burst[0]+((burst[-1]-burst[0])/2), y=(np.ones(1)*chlab)+0.3, \n",
    "                                width=burst[-1]-burst[0], height=0.05,\n",
    "                                fill_color='red', line_color='red')\n",
    "                        \n",
    "                        ##print('Im showing')\n",
    "                        \n",
    "                        \n",
    "                        \n",
    "                        \n",
    "                        ps[pind]=p1\n",
    "                        \n",
    "                        ##print('again')\n",
    "                        \n",
    "                    b=np.array(burst)\n",
    "                    tempdf=pd.DataFrame(spikes[spikes['Channel ID']==chid].iloc[0, 3:7]).T\n",
    "                     \n",
    "                    \n",
    "                   #print(tempdf, 'tempdf', tempdf.shape)\n",
    "                          \n",
    "\n",
    "                  \n",
    "\n",
    "\n",
    "\n",
    "                    tempdf['Dose Label']=dlabel\n",
    "                    tempdf['Compound ID']=compound\n",
    "                    tempdf['Experiment']=experiment\n",
    "                    tempdf['Start timestamp [µs]']=b[0]\n",
    "                    tempdf['Duration']=(np.log10(b[-1]-b[0]))\n",
    "                    tempdf['Spike Count']=len(b)\n",
    "\n",
    "                    tempdf['FT Spikes']=len(b)*100/len(spiketrain)\n",
    "\n",
    "                    tempdf['Max ISI']=max(np.log10(np.diff(b)))\n",
    "                    tempdf['Min ISI']=min(np.log10(np.diff(b)))\n",
    "                    tempdf['Mean ISI']=np.mean(np.log10(np.diff(b)))\n",
    "\n",
    "                    tempdf['Variance']=np.std(np.log10(np.diff(b)))\n",
    "\n",
    "                    tempdf['Surprise']=s\n",
    "                    tempdf['Burstiness']=burstspikes/len(spiketrain)\n",
    "                    \n",
    "                    tempdf.loc[:, 'Spikes']=[b]\n",
    "                    \n",
    "                    #print(tempdf, df, 'both')\n",
    "                          \n",
    "                          \n",
    "                          \n",
    "                          \n",
    "\n",
    "\n",
    "                    df=pd.concat([df, tempdf], axis=0)\n",
    "                    \n",
    "                    #print(df.shape, 'dfshape')\n",
    "        \n",
    "\n",
    "    from  matplotlib.colors import ListedColormap\n",
    "    \n",
    "    if plot==True:\n",
    "        \n",
    "\n",
    "        cb = ColorBar(color_mapper = color_mapper, location=(5,6))\n",
    "\n",
    "        [p.add_layout(cb, 'right') for p in ps ]              \n",
    "        [show(p) for p in ps] \n",
    "    \n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_peak_slope(b):\n",
    "    \n",
    "    st=b[0]\n",
    "    \n",
    "    isis=np.diff(b)\n",
    "    \n",
    "    minisiind=np.argmin(isis)+1\n",
    "    \n",
    "    sloperise=(1/(isis/1000000))/((b[minisiind]-b[0])/1000000)\n",
    "    \n",
    "    slopefall=(1/(isis/1000000))/((b[-1]-b[minisiind])/1000000)\n",
    "    \n",
    "    \n",
    "    \n",
    "    return (sloperise, slopefall)\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def segment(stamp, Label, Type, Duration=None):\n",
    "    \n",
    "    \n",
    "    \n",
    "    ##print(Label, 'Label')#??????\n",
    "    \n",
    "    if Type=='Spike':\n",
    "        \n",
    "        start=int(stamp[str([Label])]['start'])\n",
    "        end=int(stamp[str([Label])]['stop'])\n",
    "        ##print('end', end)\n",
    "        ##print('start', start )\n",
    "        \n",
    "    elif Type=='Burst':\n",
    "        start=int(stamp[str([Label])]['start'])\n",
    "        end=int(stamp[str([Label])]['stop'])\n",
    "        ##print('end', end)\n",
    "        ##print('start', start )\n",
    "        \n",
    "        \n",
    "    if Duration:\n",
    "        \n",
    "        end=start+(Duration*1000000)\n",
    "    \n",
    "    return (start, end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def experiment_burst_detection(folder_path, save_to, identifier1, identifier2, method_set, params_set):\n",
    "    \n",
    "    \"\"\"Function to detect bursts of single experiments and save tabular data, here folder_path=save_to (CSV)\"\"\"\n",
    "    \n",
    "    filenames=load_raw(folder_path, identifier1, identifier2)\n",
    "    stamp_dict=np.load(folder_path+'/stamp.npy', allow_pickle=True)[()]\n",
    "    \n",
    "    ##print(filenames)\n",
    "   \n",
    "    \n",
    "    for file in filenames:\n",
    "        \n",
    "        positionh5=file.index('h5')+2\n",
    "\n",
    "        stamp=stamp_dict[file[:positionh5]]\n",
    "        \n",
    "        print(stamp, 'stamp', file[:positionh5])\n",
    "        \n",
    "        ##print(stamp, 'stamp')\n",
    "        \n",
    "       \n",
    "        \n",
    "        spikes=pd.read_csv(folder_path+'/'+file)\n",
    "        \n",
    "        cols=spikes.columns\n",
    "        \n",
    "        coluname=[col for col in cols if 'Unnamed' in col]\n",
    "        \n",
    "        spikes.drop(coluname, axis=1, inplace=True)\n",
    "        \n",
    "        #print(spikes.shape, 'spikes_shape')\n",
    "        df=burst_stat(spikes, method_set, save_to, file, stamp,  params_set)\n",
    "        \n",
    "        \n",
    "        \n",
    "            \n",
    "        \n",
    "    return  filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def load_raw(path, identifier, identifier2):\n",
    "    \n",
    "    dirs = os.listdir(path)\n",
    "    \n",
    "    \n",
    "    filename=[]\n",
    "    \n",
    "   \n",
    "    \n",
    "    \n",
    "    \n",
    "    for f in dirs:\n",
    "        \n",
    "        if re.search('h5', f) and re.search(identifier, f) and re.search(identifier2, f):\n",
    "            \n",
    "            filename.append(f)\n",
    "            \n",
    "    \n",
    "            \n",
    "            \n",
    "    return filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "plogisi={'set1':[150000]}\n",
    "pmaxinterval={'set1':[100000, 200000, 200000, 3]}\n",
    "psurprise={'set1':[7]}\n",
    "\n",
    "params_set={}\n",
    "\n",
    "params_set['logisi']=plogisi\n",
    "params_set['poisson']=psurprise\n",
    "params_set['maxinterval']=pmaxinterval\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'logisi': {'set1': [150000]},\n",
       " 'poisson': {'set1': [7]},\n",
       " 'maxinterval': {'set1': [100000, 200000, 200000, 3]}}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path=r'C:\\Users\\MEA_PC\\Desktop\\AH\\Experiments\\iN\\iN39\\csv'\n",
    "save_to=r'C:\\Users\\MEA_PC\\Desktop\\AH\\Experiments\\iN\\iN39\\burst'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "b=experiment_burst_detection(folder_path, save_to, 'Veh', 'Spikes', method_set, params_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "###load spikes,   load bursts \n",
    "###plot bokeh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###load raw data for BIC control, and BIC BIC \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spikeControl=pd.read_csv(r'E:\\AH\\iN7\\iN7_0\\Pharm\\25.04.23csv'+'/' +'20220806_BIC_BP01.3BP29.4DIV72_001_Control_mwd.h5Spikes.csv')\n",
    "spikeBIC=pd.read_csv(r'E:\\AH\\iN7\\iN7_0\\Pharm\\25.04.23csv'+'/' +'20220806_BIC_BP01.3BP29.4DIV72_001_BIC50_mwd.h5Spikes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "burstControl=pd.read_csv(r'C:\\Users\\MEA_PC\\Desktop\\AH\\Experiments\\iN\\iN\\27.06.23iN7_0\\burst'+'/' +'20220806_BIC_BP01.3BP29.4DIV72_001_Control_mwd.h5PoissonBursts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "burstControlMI=pd.read_csv(r'C:\\Users\\MEA_PC\\Desktop\\AH\\Experiments\\iN\\iN\\27.06.23iN7_0\\burst'+'/' +'20220806_BIC_BP01.3BP29.4DIV72_001_Control_mwd.h5MaxIntervalBursts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bC=burstControl[(burstControl['Channel Label']==22) & (burstControl['Well Label']=='D6')]['Start timestamp [µs]'].values\n",
    "bCdurations=burstControl[(burstControl['Channel Label']==22) & (burstControl['Well Label']=='D6')]['Duration'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bCMI=burstControlMI[(burstControlMI['Channel Label']==22) & (burstControlMI['Well Label']=='D6')]['Start timestamp [µs]'].values\n",
    "bCdurationsMI=burstControlMI[(burstControlMI['Channel Label']==22) & (burstControlMI['Well Label']=='D6')]['Duration'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sC=spikeControl[(spikeControl['Channel Label']==22) & (spikeControl['Well Label']=='D6')]['Timestamp [µs]'].values\n",
    "sB=spikeBIC[(spikeBIC['Channel Label']==22) & (spikeBIC['Well Label']=='D6')]['Timestamp [µs]'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sC5sec=sC[(sC>np.median(sC)) & (sC<np.median(sC)+25000000)]\n",
    "bC5sec=bC[(bC>np.median(sC)) & (bC<np.median(sC)+25000000)]\n",
    "bC5secdur=bCdurations[(bC>np.median(sC)) & (bC<np.median(sC)+25000000)]\n",
    "bC5secdur=[10**i for i in bC5secdur]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "bC5secMI=bCMI[(bCMI>np.median(sC)) & (bCMI<np.median(sC)+25000000)]\n",
    "bC5secdurMI=bCdurationsMI[(bCMI>np.median(sC)) & (bCMI<np.median(sC)+25000000)]\n",
    "bC5secdurMI=[10**i for i in bC5secdurMI]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##in us, if I want to plot 5 sec, I need range of 1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pC=figure(width=800, height=500, y_range=(0, 5)) \n",
    "\n",
    "pC.rect(x=sC5sec, y=1, width=1000, height=0.5,\n",
    "                                fill_color='yellow', line_color='grey')\n",
    "\n",
    "pC.rect(x=bC5sec+np.array(bC5secdur)/2, y=1.5, width=bC5secdur, height=0.5,\n",
    "                                fill_color='green', line_color='green')\n",
    "pC.rect(x=bC5secMI+np.array(bC5secdurMI)/2, y=2, width=bC5secdurMI, height=0.5,\n",
    "                                fill_color='blue', line_color='blue')\n",
    "\n",
    "\n",
    "show(pC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### DTW based spike-time time sereis classification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "###Gosia, total duratio of the burst as parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### plot dynamic surprise value "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "source": [
    "1. Poisson\n",
    "a. 2-10 Threshold values \n",
    "b. PLot burst in a raster bokeh plots, annotate with suprise values\n",
    "c. PLot dit of suprise "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
